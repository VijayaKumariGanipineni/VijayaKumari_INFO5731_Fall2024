{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaKumariGanipineni/VijayaKumari_INFO5731_Fall2024/blob/main/Ganipineni_VijayaKumari_INClassExercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How state-level COVID-19 vaccination rates impacted infection and mortality trends over time in the U.S.**\n",
        "This study involve analyzing correlations between vaccination coverage and the rate of infections or deaths across states.\n",
        "\n",
        "### Data Collection:\n",
        "\n",
        "1. **Vaccination Data**: Obtaining daily state-level vaccination data from Kaggle’s dataset at (https://www.kaggle.com/datasets/paultimothymooney/usa-covid19-vaccinations).\n",
        "2. **Infection & Mortality Data**: Using CDC or Johns Hopkins databases for infection and mortality counts.\n",
        "3. **Timeline**: Collecting a year’s worth of data to capture dynamic changes, roughly 365 data points per state.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "- **Merge Data**: Combining vaccination, infection, and mortality data based on state and date.\n",
        "- **Data Storage**: Saving the merged data in CSV files for accessibility.\n",
        "- **Tools**: Using Python (Pandas) for analysis, and performing statistical tests or regression modeling to assess the impact of vaccination rates.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GTGeKZiejJSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading the local dataset to Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will allow to upload the dataset manually\n",
        "\n",
        "# Checking the uploaded file names\n",
        "for file_name in uploaded.keys():\n",
        "    print(file_name)  # This will print the name of the file  uploaded\n",
        "\n",
        "# Using the correct file name in the code\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Reading the uploaded file\n",
        "df = pd.read_csv(io.BytesIO(uploaded['us_state_vaccination.csv']))\n",
        "\n",
        "#  Sampling the 1000 random rows from the dataset\n",
        "sampled_data = df.sample(n=1000, random_state=42)\n",
        "\n",
        "# Step 5: Saving the sampled data to a new CSV file\n",
        "sampled_data.to_csv(\"sampled_vaccination_data.csv\", index=False)\n",
        "\n",
        "# Step 6: Downloading the sampled dataset\n",
        "files.download(\"sampled_vaccination_data.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4XvRknixTh1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d69d3306-3771-4ece-8f91-56806a7e7aa3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f82a848-5127-4c97-9b48-f64bb7a0f0b2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f82a848-5127-4c97-9b48-f64bb7a0f0b2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving us_state_vaccination.csv to us_state_vaccination.csv\n",
            "us_state_vaccination.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0bcff074-1f23-49f3-be53-cf0e33e58338\", \"sampled_vaccination_data.csv\", 87470)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YaGLbSHHB8Ej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "f3073843-f828-4ac1-f7c9-545d8d6cd01a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38a49c59-b1c6-4194-86bc-a70c7cc3317a\", \"fetched_articles.csv\", 1088129)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Title  \\\n",
              "0                          XYZ arm (XYZ robotic arm)   \n",
              "1                               Testing metadata xyz   \n",
              "2                               Testing metadata xyz   \n",
              "3                               Testing metadata xyz   \n",
              "4                                   PEG‐XYZ, peg‐XYZ   \n",
              "5                              BIO-XYZ, What is XYZ?   \n",
              "6  Payroll Information System Based On Pt XYZ Cas...   \n",
              "7                                              [XYZ]   \n",
              "8                                                XYZ   \n",
              "9  Independent Transversal Domination Number for ...   \n",
              "\n",
              "                                               Venue  Year  \\\n",
              "0  The Dictionary of Genomics, Transcriptomics an...     0   \n",
              "1                                                        0   \n",
              "2                                                        0   \n",
              "3                                                        0   \n",
              "4                              Catalysis from A to Z     0   \n",
              "5  Current Trends in Biomedical Engineering &amp;...     0   \n",
              "6                                                        0   \n",
              "7                     New Palauan-English Dictionary  2019   \n",
              "8                              Dictionary of Biology  2014   \n",
              "9  Turkish Journal of Mathematics and Computer Sc...     0   \n",
              "\n",
              "                                  Authors  \\\n",
              "0                                           \n",
              "1                                           \n",
              "2                                           \n",
              "3                                           \n",
              "4                             Noir B.L.C.   \n",
              "5                       Nandy Subir Kumar   \n",
              "6  Mahendra Muchammad David, Eviyanti Ade   \n",
              "7                                           \n",
              "8                                           \n",
              "9                       ATAY ATAKUL Betül   \n",
              "\n",
              "                                            Abstract  \n",
              "0                                                     \n",
              "1                                                     \n",
              "2                                                     \n",
              "3                                                     \n",
              "4                                                     \n",
              "5                                                     \n",
              "6                                                     \n",
              "7                                                     \n",
              "8                                                     \n",
              "9  <jats:p xml:lang=\"en\">A dominating set of a gr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74d390af-df38-4868-9c72-2f610ffedac8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Venue</th>\n",
              "      <th>Year</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XYZ arm (XYZ robotic arm)</td>\n",
              "      <td>The Dictionary of Genomics, Transcriptomics an...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Testing metadata xyz</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Testing metadata xyz</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Testing metadata xyz</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PEG‐XYZ, peg‐XYZ</td>\n",
              "      <td>Catalysis from A to Z</td>\n",
              "      <td>0</td>\n",
              "      <td>Noir B.L.C.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BIO-XYZ, What is XYZ?</td>\n",
              "      <td>Current Trends in Biomedical Engineering &amp;amp;...</td>\n",
              "      <td>0</td>\n",
              "      <td>Nandy Subir Kumar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Payroll Information System Based On Pt XYZ Cas...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Mahendra Muchammad David, Eviyanti Ade</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[XYZ]</td>\n",
              "      <td>New Palauan-English Dictionary</td>\n",
              "      <td>2019</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XYZ</td>\n",
              "      <td>Dictionary of Biology</td>\n",
              "      <td>2014</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Independent Transversal Domination Number for ...</td>\n",
              "      <td>Turkish Journal of Mathematics and Computer Sc...</td>\n",
              "      <td>0</td>\n",
              "      <td>ATAY ATAKUL Betül</td>\n",
              "      <td>&lt;jats:p xml:lang=\"en\"&gt;A dominating set of a gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74d390af-df38-4868-9c72-2f610ffedac8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74d390af-df38-4868-9c72-2f610ffedac8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74d390af-df38-4868-9c72-2f610ffedac8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ea62a7e-2fdf-4c7e-980c-e7a4d7c31b0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ea62a7e-2fdf-4c7e-980c-e7a4d7c31b0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ea62a7e-2fdf-4c7e-980c-e7a4d7c31b0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_articles",
              "summary": "{\n  \"name\": \"df_articles\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 890,\n        \"samples\": [\n          \"spacesXYZ: CIE XYZ and some of Its Derived Color Spaces\",\n          \"High-speed XYZ-nanopositioner for scanning ion conductance microscopy\",\n          \"Analisis Perancangan Model Dashboard dalam Monitoring Data Pelanggan ( Studi Kasus : Toko Xyz )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Venue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 553,\n        \"samples\": [\n          \"Jurnal Riset Manajemen dan Bisnis (JRMB) Fakultas Ekonomi UNIAT\",\n          \"MALCOM: Indonesian Journal of Machine Learning and Computer Science\",\n          \"LIBRARIA: Jurnal Perpustakaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 881,\n        \"min\": 0,\n        \"max\": 2024,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2022,\n          2024,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 837,\n        \"samples\": [\n          \"Zenkova Zhanna, Musoni Wilson, Tarima Sergey\",\n          \"Oktaviani Dickta, Sari Liska Marlinda\",\n          \"Song Weiming\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 617,\n        \"samples\": [\n          \"<jats:p>&lt;p class=\\\"Pendahuluan\\\"&gt;Since the happening of increase of oil price in August 2005, PT. XYZ starts to think over to use the source of other alternative energy specially to replace HTM burner and steam boiler which still use IDO and diesel fuel. Source of alternative energy is coal because the source of coal in Indonesia is in a large amount. Because of that PT. XYZ plans to change HTM burner and steam boiler with coal boiler. Analysis eligibility of investment of coal boiler is needed to evaluate from technical aspect and monetery asect which assign value and time return of most optimal investment. The method that use for that analysis are payback period, net present value, profitability index and internal rate of return in three condition that is pessimist condition, normal condition and optimism condition. Besides also analyze influence of project investment to production cost at that condition. Investment of coal boiler project is suitable.&lt;/p&gt;&lt;p class=\\\"Pendahuluan\\\"&gt;\\u00a0&lt;/p&gt;&lt;p class=\\\"Pendahuluan\\\"&gt;Keywords : Production cost, payback period, net present value, index profitability, internal rate of return.&lt;/p&gt;</jats:p>\",\n          \"<jats:p>This study aims to determine whether there is influence of leadership style, motivation and work discipline on employee performance at PT XYZ Cikarang. This research was conducted to determine the decline in the annual production rate at the company. This research was conducted at PT XYZ Cikarang, by taking 82 employees as research samples using purposive sampling technique. Collecting data using observation methods and questionnaires. The data analysis technique used is multiple regression analysis. Based on the study conduct, the results of the analysis showed that leadership style and work discipline have effect on employee performance.</jats:p>\",\n          \"<jats:p>This research examines inventory management at the XYZ Hospital Pharmacy Installation in Bandung, with a special focus on medicines and medical devices. The background to this research is the significant increase in health costs and the importance of effective supply chain management to reduce unnecessary costs. Based on monthly stock and daily sales data from October 2023 to February 2024, this research uses quantitative methods to calculate optimal inventory levels, including Economic Order Quantity (EOQ), safety stock, and reorder point (ROP). This research also applies ABC analysis and cycle counting to prioritize inventory control. The research results show that the proposed inventory policy, especially the continuous review strategy, has the potential for significant cost savings for the XYZ Hospital Pharmacy Installation. For pharmaceutical products, achieving a 99% service level can result in savings of IDR 302,697,429, which is 48.17% of the average inventory level. For medical devices, potential savings reach IDR 70,602,064, which is 48.77% of the average inventory level. The total potential savings for all products is IDR 373,299,493. These findings highlight that hospitals currently do not have effective controls in managing inventory of single-use medical devices. Implementing strong inventory policies and procedures is critical to improving cost efficiency and optimizing inventory levels within an organization.</jats:p>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "# Defining constants\n",
        "API_URL = 'https://api.crossref.org/works'\n",
        "QUERY = 'XYZ'\n",
        "NUM_ARTICLES = 1000\n",
        "START_YEAR = 2014\n",
        "END_YEAR = 2024\n",
        "RETRY_LIMIT = 5  # Number of retry attempts\n",
        "RETRY_DELAY = 5  # Initial delay in seconds\n",
        "\n",
        "# A function to fetch articles from CrossRef with rate limit handling\n",
        "def fetch_articles(query, num_articles, start_year, end_year):\n",
        "    all_articles = []\n",
        "    search_params = {\n",
        "        'query': query,\n",
        "        'rows': 100,  # Maxmum results per request\n",
        "        'filter': f'from-pub-date:{start_year}-01-01,until-pub-date:{end_year}-12-31',\n",
        "        'select': 'title,container-title,published-print,author,abstract'\n",
        "    }\n",
        "\n",
        "    retry_count = 0\n",
        "    while len(all_articles) < num_articles:\n",
        "        try:\n",
        "            response = requests.get(API_URL, params=search_params)\n",
        "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "            if response.status_code == 429:  #This is to alert when rate limit is exceeded\n",
        "                retry_count += 1\n",
        "                if retry_count > RETRY_LIMIT:\n",
        "                    print(\"Rate limit exceeded. Stopping execution.\")\n",
        "                    break\n",
        "                wait_time = RETRY_DELAY * (2 ** (retry_count - 1))  # Exponential backoff\n",
        "                print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                continue\n",
        "\n",
        "            data = response.json()\n",
        "            papers = data.get('message', {}).get('items', [])\n",
        "\n",
        "            if not papers:\n",
        "                break\n",
        "\n",
        "            for paper in papers:\n",
        "                article = {\n",
        "                    'Title': paper.get('title', [''])[0],\n",
        "                    'Venue': paper.get('container-title', [''])[0],\n",
        "                    'Year': paper.get('published-print', {}).get('date-parts', [[0]])[0][0],\n",
        "                    'Authors': ', '.join(author.get('family', '') + ' ' + author.get('given', '') for author in paper.get('author', [])),\n",
        "                    'Abstract': paper.get('abstract', '')\n",
        "                }\n",
        "                all_articles.append(article)\n",
        "                if len(all_articles) >= num_articles:\n",
        "                    break\n",
        "\n",
        "            # Pagination: adjust the 'offset' parameter to fetch next set of results\n",
        "            search_params['offset'] = search_params.get('offset', 0) + 100\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error fetching data: {e}\")\n",
        "            break\n",
        "\n",
        "    return all_articles\n",
        "\n",
        "# Fetching articles and convert to DataFrame\n",
        "articles = fetch_articles(QUERY, NUM_ARTICLES, START_YEAR, END_YEAR)\n",
        "df_articles = pd.DataFrame(articles)\n",
        "\n",
        "\n",
        "# Saving the data to a CSV file\n",
        "df_articles.to_csv('fetched_articles.csv', index=False)\n",
        "\n",
        "# Downloading the CSV file\n",
        "files.download('fetched_articles.csv')\n",
        "# Displaying the first five rows of the dataframe\n",
        "df_articles.head(10)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtKskTzbCLaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "a3ef0f56-4609-4e23-b8bb-13c5d4087848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title               Author  \\\n",
            "0                           Trump 2020 vs Trump 2024  lostredditorlurking   \n",
            "1  Trump’s Vice President says Trump should never...         Redditname97   \n",
            "2          Eminem gets flustered talking about Trump       Wild-Army-6085   \n",
            "3  Trump says illegal immigrants are “eating the ...   SkillImmediate6393   \n",
            "4  What are your thoughts on the Harris and Trump...        anderson01832   \n",
            "5  Biden poses with kids wearing Trump T-shirts i...           knowitokay   \n",
            "6  Former President Trump after the presidential ...        WeaponHex1638   \n",
            "7  Trump during the Moment of Silence at the 9/11...          CrispyMiner   \n",
            "8  Former President Trump during the presidential...                 mtaw   \n",
            "9                 Trump rejects second Harris debate           Rivinstein   \n",
            "\n",
            "           Subreddit   Score  Number of Comments   Created UTC  \\\n",
            "0  interestingasfuck   61271                2593  1.723528e+09   \n",
            "1  interestingasfuck  146511                4683  1.722234e+09   \n",
            "2             Eminem   21935                3080  1.709100e+09   \n",
            "3  interestingasfuck  149090                6871  1.726019e+09   \n",
            "4          AskReddit   20352               27694  1.726022e+09   \n",
            "5               pics   92284               11971  1.726138e+09   \n",
            "6               pics  122374                9327  1.726036e+09   \n",
            "7               pics  102223                8938  1.726069e+09   \n",
            "8               pics   63532                6690  1.726054e+09   \n",
            "9           politics   56722                6590  1.726169e+09   \n",
            "\n",
            "                                                 URL  \n",
            "0                    https://v.redd.it/rkycdkg4edid1  \n",
            "1                    https://v.redd.it/zowlh9cegefd1  \n",
            "2                    https://v.redd.it/hu31eeslm9lc1  \n",
            "3                    https://v.redd.it/0k02w6gl43od1  \n",
            "4  https://www.reddit.com/r/AskReddit/comments/1f...  \n",
            "5               https://i.redd.it/ho7s2v3eycod1.jpeg  \n",
            "6               https://i.redd.it/kqzr1ww9k4od1.jpeg  \n",
            "7               https://i.redd.it/s893o1rra7od1.jpeg  \n",
            "8               https://i.redd.it/bqo3dimqz5od1.jpeg  \n",
            "9  https://www.cnbc.com/2024/09/12/trump-rejects-...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c89fff98-aa5c-4376-8403-995cbcf2c514\", \"reddit_data.csv\", 46429)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# write your answer here\n",
        "\n",
        "# Import necessary modules\n",
        "import logging#hide all warnings and messages logged by praw that are below the ERROR level (such as INFO, WARNING, etc.).\n",
        "\n",
        "# Set the logging level for the 'praw' module to 'ERROR' to suppress warnings\n",
        "logging.getLogger(\"praw\").setLevel(logging.ERROR)\n",
        "\n",
        "#  PRAW initialization and data collection\n",
        "import praw\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Reddit API credentials (I have altered after running the codes for my security)(If u need my reddit credentials I can submit personally)\n",
        "CLIENT_ID = 'O01Bu9MMEdpfYrF9exIJCzg'\n",
        "CLIENT_SECRET = 'K0bQhSzmvgcd2U0NmBUSQZx66o4dv7Q'\n",
        "USER_AGENT = 'I need to collect data to complete an assignment'\n",
        "\n",
        "# Initializing Reddit instance\n",
        "reddit = praw.Reddit(client_id=CLIENT_ID,\n",
        "                     client_secret=CLIENT_SECRET,\n",
        "                     user_agent=USER_AGENT)\n",
        "\n",
        "# Data collection from Reddit based on a keyword 'trump'\n",
        "def fetch_reddit_data(keyword, limit=1000):\n",
        "    posts_data = []\n",
        "\n",
        "    # Search for submissions using the keyword\n",
        "    for submission in reddit.subreddit('all').search(keyword, limit=limit):\n",
        "        posts_data.append({\n",
        "            'Title': submission.title,\n",
        "            'Author': submission.author.name if submission.author else 'N/A',\n",
        "            'Subreddit': submission.subreddit.display_name,\n",
        "            'Score': submission.score,\n",
        "            'Number of Comments': submission.num_comments,\n",
        "            'Created UTC': submission.created_utc,\n",
        "            'URL': submission.url\n",
        "        })\n",
        "\n",
        "    # Convert the results to a Pandas DataFrame\n",
        "    df = pd.DataFrame(posts_data)\n",
        "    return df\n",
        "\n",
        "# Collect Reddit data with the keyword 'trump'\n",
        "keyword = 'trump'  # My desired desired keyword\n",
        "reddit_data_df = fetch_reddit_data(keyword, limit=1000)\n",
        "\n",
        "# Displaying the first 10 rows of the dataframe to show that am actually doing something\n",
        "print(reddit_data_df.head(10))\n",
        "\n",
        "# Saving the data to a CSV file\n",
        "reddit_data_df.to_csv('fetched_reddit_data.csv', index=False)\n",
        "\n",
        "# Downloading the CSV file\n",
        "files.download('fetched_reddit_data.csv')\n",
        "\n",
        "#End\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "I can honestly attest to gaining skills which when practicing can make me a real pro.\n",
        "The web scaping part was particularly hard since the social media sites expected credentials and was blocking in nature. The other areas didnt have much tough. After a struggle, I settled for the Reddit API though it requires caution as one can easily take away your account.\n",
        "The exercise has made me learn that I don't need to scroll the whole Reddit or any other social media when I can just scrape the data I need through few lines of code.\n",
        "I look forward to going through more rigorous exercises like thes ones as they are a sure way of making my research skills great.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4cc8c73d-06f2-4edf-8e79-958e3aca2dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nI can honestly attest to gaining skills which when nurtured can make me a real pro.\\nThe web scaping part was particularly hard since the social media sites expected credentials and was bvlocking in nature. The other areas didnt have much fuss. After a struggle, I settled for the Reddit API though it requires caution as one can easily take away your account.\\nThe exercise has made me learn that I don't need to scroll the whole Reddit or any other social media when I can just scrape the data I need through few lines of code.\\nI look forward to going through more rigorous exercises like thes ones as they are a sure way of making my research skills great.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}