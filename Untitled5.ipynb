{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMndLsfnIOKuNwMSnUwu00f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaKumariGanipineni/VijayaKumari_INFO5731_Fall2024/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "wa44WfWIbG5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "rh7bAR23g0yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Replace this with your actual API key\n",
        "API_KEY = \"5e9c935ba0bd02a4bc2875d826e04237\"\n",
        "\n",
        "headers = {\n",
        "    'X-ELS-APIKey': API_KEY,\n",
        "    'Accept': 'application/json'\n",
        "}\n",
        "\n",
        "\n",
        "# Define the base URL for the ScienceDirect API (or Scopus API for broader search)\n",
        "BASE_URL = 'https://www.sciencedirect.com/topics/social-sciences/autonomous-driving'\n",
        "\n",
        "# Parameters for the query\n",
        "params = {\n",
        "    'query': 'autonomous driving',\n",
        "    'count': 25,  # Limit to the number of articles you want to retrieve\n",
        "    'httpAccept': 'application/json',\n",
        "}\n",
        "\n",
        "# Send the request to Elsevier's API\n",
        "response = requests.get(BASE_URL, headers=headers, params=params)\n",
        "\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON response\n",
        "    data = response.json()\n",
        "    articles = data['search-results']['entry']\n",
        "\n",
        "    # Extract required fields\n",
        "    titles = []\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "    years = []\n",
        "    journals = []\n",
        "    keywords = []\n",
        "    abstracts = []\n",
        "    dois = []\n",
        "    urls = []\n",
        "\n",
        "    for article in articles:\n",
        "        titles.append(article.get('dc:title', 'N/A'))\n",
        "        authors.append(', '.join([author['$'] for author in article.get('authors', {}).get('author', [])]))\n",
        "        affiliations.append(article.get('affiliation', 'N/A'))\n",
        "        years.append(article.get('prism:coverDate', 'N/A')[:4])  # Extract the year only\n",
        "        journals.append(article.get('prism:publicationName', 'N/A'))\n",
        "        keywords.append(article.get('authkeywords', 'N/A'))\n",
        "        abstracts.append(article.get('dc:description', 'N/A'))\n",
        "        dois.append(article.get('prism:doi', 'N/A'))\n",
        "        urls.append(article.get('link', [{}])[0].get('@href', 'N/A'))\n",
        "\n",
        "    # Create a pandas DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'Title': titles,\n",
        "        'Authors': authors,\n",
        "        'Affiliation': affiliations,\n",
        "        'Year': years,\n",
        "        'Journal': journals,\n",
        "        'Keywords': keywords,\n",
        "        'Abstract': abstracts,\n",
        "        'DOI': dois,\n",
        "        'URL': urls\n",
        "    })\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv('autonomous_driving_articles.csv', index=False)\n",
        "    print(\"Data extraction and CSV generation successful!\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn2qK3MWg2PY",
        "outputId": "5c0e2801-8a04-4d37-dbbe-e3e9fa275937"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve data. Status code: 403\n"
          ]
        }
      ]
    }
  ]
}